{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install seqeval evaluate -q","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\nimport argparse\nfrom itertools import chain\nfrom functools import partial\nimport gc\nimport pickle as pkl\n\nfrom sklearn.model_selection import KFold\nimport torch\nfrom transformers import AutoTokenizer, Trainer, TrainingArguments\nfrom transformers import AutoModelForTokenClassification, DataCollatorForTokenClassification\nimport evaluate\nfrom datasets import Dataset, features\nimport numpy as np","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Обучение моделей\nВ решении были использованы модели https://huggingface.co/microsoft/deberta-v3-large и https://huggingface.co/microsoft/deberta-v3-base. Они обучались для определения большей части меток. Другая часть меток была найдена с помощью регулярных выражений. При обучении моделей был использован взвешаный Log loss, с весами пропорциональными частоте меток в обучающем наборе. Обучающий набор был дополнен данными, которые описаны в https://www.kaggle.com/competitions/pii-detection-removal-from-educational-data/discussion/473139, таким образом, чтобы содержалось хотя бы 100 примеров для каждого класса.\n\nДалее показано как обучалась одна модель на одном фолде.","metadata":{}},{"cell_type":"code","source":"old_data = json.load(open(\"/kaggle/input/pii-detection-removal-from-educational-data/train.json\"))\n\np = []\nn = []\n\nfor d in old_data:\n    if any(np.array(d[\"labels\"]) != \"O\"):\n        p.append(d)\n    else:\n        n.append(d)\nmore_1 = json.load(open(\"/kaggle/input/more-pii-data-2/data_1.json\"))\nmore_2 = json.load(open(\"/kaggle/input/more-pii-data-2/data_2.json\"))\n\ndata = p + more_1[:275] + more_2[:250]\ndata = data + n[:(3 * len(data)) // 2]\nprint(\"sum datapoints: \", len(data))\n\nno_labels = {\"B-PHONE_NUM\", \"I-PHONE_NUM\", \"B-EMAIL\"}\nfor d in data:\n    for i in range(len(d[\"labels\"])):\n        if d[\"labels\"][i] in no_labels:\n            d[\"labels\"][i] = \"O\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_labels = sorted(list(set(chain(*[x[\"labels\"] for x in data]))))\nlabel2id = {l: i for i,l in enumerate(all_labels)}\nid2label = {v: k for k,v in label2id.items()}\ntarget = list(list(label2id.keys())[:-1])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tokenize(example, tokenizer, label2id):\n    text = []\n\n    labels = [] # Метки побуквеннно с пробелами\n    targets = [] \n\n    for t, l, ws in zip(example[\"tokens\"], example[\"provided_labels\"], example[\"trailing_whitespace\"]):\n\n        text.append(t)\n        labels.extend([l]*len(t))\n        \n        if l in target:\n            targets.append(1)\n        else:\n            targets.append(0)\n        if ws:\n            text.append(\" \")\n            labels.append(\"O\")\n\n\n    tokenized = tokenizer(\"\".join(text), return_offsets_mapping=True, truncation=True, max_length=TRAINING_MAX_LENGTH)\n    \n    target_num = sum(targets)\n    labels = np.array(labels)\n\n    text = \"\".join(text)\n    token_labels = []\n\n    for start_idx, end_idx in tokenized.offset_mapping:\n        if start_idx == 0 and end_idx == 0: \n            token_labels.append(label2id[\"O\"])\n            continue\n        if text[start_idx].isspace():\n            start_idx += 1\n\n        token_labels.append(label2id[labels[start_idx]])\n\n    length = len(tokenized.input_ids)\n\n    return {\n        **tokenized,\n        \"labels\": token_labels,\n        \"length\": length,\n        \"target_num\": target_num,\n        \"group\": 1 if target_num > 0 else 0\n    }","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(TRAINING_MODEL_PATH)\n\nds = Dataset.from_dict({\n    \"full_text\": [x[\"full_text\"] for x in data], # Полный текст\n    \"document\": [str(x[\"document\"]) for x in data], # Номер документа\n    \"tokens\": [x[\"tokens\"] for x in data], # Исходные токены \n    \"trailing_whitespace\": [x[\"trailing_whitespace\"] for x in data], # Есть ли пробел после исходного токена\n    \"provided_labels\": [x[\"labels\"] for x in data], # Исходные метки\n})","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds = ds.map(tokenize, fn_kwargs={\"tokenizer\": tokenizer, \"label2id\": label2id}, num_proc=1)\nds = ds.class_encode_column(\"group\")\nprint(ds)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nfolds = 3\nseed = 42\nfold = 0\n\nds = ds.shuffle(seed=seed)\ntrain_idxs, test_idxs = list(KFold(n_splits=nfolds, random_state=seed, shuffle=True).split(ds))[fold]\ntrain_ds = Dataset.from_dict(ds[train_idxs])\ntest_ds = Dataset.from_dict(ds[test_idxs])\nold_docs = {d[\"document\"] for d in old_data}\nidxs = []\nfor i, d in enumerate(test_ds):\n    if d[\"document\"].isdigit() and int(d[\"document\"]) in old_docs:\n        idxs.append(i)\n\ntest_ds = Dataset.from_dict(test_ds[idxs])\n\ndel ds\ngc.collect()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from seqeval.metrics import recall_score, precision_score\nfrom seqeval.metrics import classification_report\nfrom seqeval.metrics import f1_score\n\ndef compute_metrics(p, all_labels):\n    predictions, labels = p\n    predictions = np.argmax(predictions, axis=2)\n\n    true_predictions = [\n        [all_labels[p] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n    true_labels = [\n        [all_labels[l] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n    \n    recall = recall_score(true_labels, true_predictions)\n    precision = precision_score(true_labels, true_predictions)\n    beta = 5\n    f_score = (1 + beta ** 2) * recall * precision / (beta ** 2 * precision + recall + 1e-9)\n    \n    results = {\n        'recall': recall,\n        'precision': precision,\n        'f_beta': f_score\n    }\n    return results","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForTokenClassification.from_pretrained(\n    TRAINING_MODEL_PATH,\n    num_labels=len(all_labels),\n    id2label=id2label,\n    label2id=label2id,\n    ignore_mismatched_sizes=True\n)\ncollator = DataCollatorForTokenClassification(tokenizer, pad_to_multiple_of=16)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FREEZE_EMBEDDINGS = True\nFREEZE_LAYERS = 7\n\nif FREEZE_EMBEDDINGS:\n    print('Freezing embeddings.')\n    for param in model.deberta.embeddings.parameters():\n        param.requires_grad = False\n        \nif FREEZE_LAYERS > 0:\n    print(f'Freezing {FREEZE_LAYERS} layers.')\n    for layer in model.deberta.encoder.layer[:FREEZE_LAYERS]:\n        for param in layer.parameters():\n            param.requires_grad = False","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"args = TrainingArguments(\n    output_dir=OUTPUT_DIR, \n    fp16=True,\n    # optim=\"adafactor\",\n    gradient_accumulation_steps=4,\n    gradient_checkpointing=True,\n    learning_rate=2e-5,\n    num_train_epochs=2,\n    per_device_train_batch_size=1,\n    per_device_eval_batch_size=1,\n    report_to=\"none\",\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    gradient_checkpointing_kwargs={'use_reentrant': False},\n    save_total_limit=1,\n    overwrite_output_dir=True,\n    load_best_model_at_end=True,\n    lr_scheduler_type='cosine',\n    metric_for_best_model=\"f1\",\n    greater_is_better=True,\n    weight_decay=0.01\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn.functional as F\nimport torch\nfrom torch.nn import BCEWithLogitsLoss, CrossEntropyLoss\n\nloss_fn = CrossEntropyLoss(weight=torch.Tensor([7, 5, 7, 7, 7, 7, 5, 7, 7, 1]).to(device='cuda:0'))\n\ndef sent_loss(logits, labels):\n    l = 1.0\n    return F.cross_entropy(logits, labels)\n    \n\nclass CustomTrainer(Trainer):\n    def compute_loss(self, model, inputs, return_outputs=False):\n        labels = torch.flatten(inputs.pop(\"labels\"), start_dim=0, end_dim=1)\n        outputs = model(**inputs)\n        ignore_index = labels.int()\n\n        flat_outputs = outputs.logits.squeeze()[ignore_index != -100]\n        flat_labels = labels.squeeze()[ignore_index != -100]\n        loss = loss_fn(flat_outputs, flat_labels)\n\n        return (loss, outputs) if return_outputs else loss","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = CustomTrainer(\n    model=model, \n    args=args, \n    train_dataset=train_ds, \n    eval_dataset=test_ds, \n    data_collator=collator, \n    tokenizer=tokenizer,\n    compute_metrics=partial(compute_metrics, all_labels=all_labels),\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ntrainer.train()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Значения метрик на кросс-валидации для deberta-v3-large\nМетрики были посчитаны для изначального набора данных, без добавленных.\n\n|   | fold 0   | fold 1 | fold 2 | mean |\n|-----|----------|----------|----------|---|\n| F5    | $0.966247943171328$   |  $0.963711492042711$  | $0.962475756809174$ | $0.9641450640077377$ |\n\n### Значения метрик на кросс-валидации для deberta-v3-base\n\n|   | fold 0   | fold 1 | fold 2 | mean |\n|-----|----------|----------|----------|---|\n| F5    | $0.956667331074347$   |  $0.954059829059829$  | $0.956017079136094$ | $0.95558141309009$ |","metadata":{}},{"cell_type":"markdown","source":"## Посылка решения\nВеса для предсказаний моделей были выбраны пропорцианально значениям метрик на кросс валидации. Усреднение меток между можелями было произведено на токенах, требуемых в задаче.","metadata":{}},{"cell_type":"code","source":"max_len = 3500\n\ndef tokenize(example, tokenizer):\n    text = []\n    token_map = []\n    idx = 0\n    for t, ws in zip(example[\"tokens\"], example[\"trailing_whitespace\"]):\n        text.append(t)\n        token_map.extend([idx]*len(t))\n        if ws:\n            text.append(\" \")\n            token_map.append(-1)\n        idx += 1\n    tokenized = tokenizer(\"\".join(text), return_offsets_mapping=True, truncation=True, max_length=max_len)\n    return {\n        **tokenized,\n        \"token_map\": token_map,\n    }","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = json.load(open(\"/kaggle/input/pii-detection-removal-from-educational-data/test.json\"))\nds = Dataset.from_dict({\n    \"full_text\": [x[\"full_text\"] for x in data],\n    \"document\": [x[\"document\"] for x in data],\n    \"tokens\": [x[\"tokens\"] for x in data],\n    \"trailing_whitespace\": [x[\"trailing_whitespace\"] for x in data],\n})\n\nmodel_paths = {\n    '/kaggle/input/debertav3-base-cl-fold-0' : 0.956667331074347,\n    '/kaggle/input/debertav3-base-cl-fold-1': 0.954059829059829,\n    '/kaggle/input/debertav3-base-cl-fold-2' : 0.956017079136094\n}\n\nfirst_model_path = list(model_paths.keys())[0]\ntokenizer = AutoTokenizer.from_pretrained(first_model_path)\nds = ds.map(tokenize, fn_kwargs={\"tokenizer\": tokenizer}, num_proc=1)\n\nall_preds = []\n\ntotal_weight = sum(model_paths.values())\n\nfor model_path, weight in model_paths.items():\n    model = AutoModelForTokenClassification.from_pretrained(model_path)\n    collator = DataCollatorForTokenClassification(tokenizer, pad_to_multiple_of=16)\n    \n    args = TrainingArguments(\n        \".\", \n        per_device_eval_batch_size=1, \n        report_to=\"none\",\n    )\n    \n    trainer = Trainer(\n        model=model, \n        args=args, \n        data_collator=collator, \n        tokenizer=tokenizer,\n    )\n\n    if len(all_preds) == 0:\n        all_preds = softmax(trainer.predict(ds).predictions, axis = -1) * weight\n    else:\n        all_preds += softmax(trainer.predict(ds).predictions, axis = -1) * weight\n    \n    del model, trainer\n    torch.cuda.empty_cache()\n    gc.collect()\n\nweighted_average_predictions = all_preds / total_weight\nfinal_predictions = []\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for p, token_map, offsets, tokens, doc in zip(weighted_average_predictions, ds[\"token_map\"], ds[\"offset_mapping\"], ds[\"tokens\"], ds[\"document\"]):\n    pairs = set()\n    current_predictions = {}\n    for prob, (start_idx, end_idx) in zip(p, offsets):\n        if start_idx + end_idx == 0: \n            continue\n        if token_map[start_idx] == -1:\n            start_idx += 1\n        while start_idx < len(token_map) and tokens[token_map[start_idx]].isspace():\n            start_idx += 1\n        if start_idx >= len(token_map): \n            break\n        token_id = token_map[start_idx]\n        pair = (doc, token_id)\n        if pair in pairs:\n            continue\n        current_predictions[token_id] = prob\n        pairs.add(pair)\n    final_predictions.append(current_predictions)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del ds, weighted_average_predictions, all_preds\ngc.collect()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds = Dataset.from_dict({\n    \"full_text\": [x[\"full_text\"] for x in data],\n    \"document\": [x[\"document\"] for x in data],\n    \"tokens\": [x[\"tokens\"] for x in data],\n    \"trailing_whitespace\": [x[\"trailing_whitespace\"] for x in data],\n})\n\ndel data\ngc.collect()\n\nmodel_paths = {\n    '/kaggle/input/debertav3-large-cl-fold-0': 0.966247943171328,\n    '/kaggle/input/debertav3-large-cl-fold-1': 0.963711492042711,\n    '/kaggle/input/debertav3-large-cl-fold-2': 0.962475756809174\n}\n\nfirst_model_path = list(model_paths.keys())[0]\ntokenizer = AutoTokenizer.from_pretrained(first_model_path)\nds = ds.map(tokenize, fn_kwargs={\"tokenizer\": tokenizer}, num_proc=1)\n\nall_preds = []\n\ntotal_weight = sum(model_paths.values())\n\nfor model_path, weight in model_paths.items():\n    tokenizer = AutoTokenizer.from_pretrained(model_path)\n    model = AutoModelForTokenClassification.from_pretrained(model_path)\n    collator = DataCollatorForTokenClassification(tokenizer, pad_to_multiple_of=16)\n    \n    args = TrainingArguments(\n        \".\", \n        per_device_eval_batch_size=1, \n        report_to=\"none\",\n    )\n    \n    trainer = Trainer(\n        model=model, \n        args=args, \n        data_collator=collator, \n        tokenizer=tokenizer,\n    )\n\n    if len(all_preds) == 0:\n        all_preds = softmax(trainer.predict(ds).predictions, axis =-1) * weight\n    else:\n        all_preds += softmax(trainer.predict(ds).predictions, axis=-1) * weight\n    \n    del model, trainer\n    torch.cuda.empty_cache()\n    gc.collect()\n\nweighted_average_predictions = all_preds / total_weight","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idx = 0\nw_1 = 0.955581413 / (0.964145064 + 0.955581413)\nw_2 = 1.0 - w_1\n\nfor p, token_map, offsets, tokens, doc in zip(weighted_average_predictions, ds[\"token_map\"], ds[\"offset_mapping\"], ds[\"tokens\"], ds[\"document\"]):\n    pairs = set()\n    for prob, (start_idx, end_idx) in zip(p, offsets):\n        if start_idx + end_idx == 0: \n            continue\n        if token_map[start_idx] == -1:\n            start_idx += 1\n        while start_idx < len(token_map) and tokens[token_map[start_idx]].isspace():\n            start_idx += 1\n        if start_idx >= len(token_map): \n            break\n        token_id = token_map[start_idx]\n        pair = (doc, token_id)\n        if pair in pairs:\n            continue\n        if token_id not in final_predictions[idx]:\n            final_predictions[idx][token_id] = prob\n        else:\n            final_predictions[idx][token_id] = w_1 * final_predictions[idx][token_id] + w_2 * prob\n        pairs.add(pair)\n    idx += 1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del all_preds\ngc.collect()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config = json.load(open(\"/kaggle/input/debertav3-base-cl-fold-0/config.json\"))\nid2label = config[\"id2label\"]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"document, token, label, token_str = [], [], [], []\nurl_regex = re.compile(\"^https?:\\\\/\\\\/(?:www\\\\.)?[-a-zA-Z0-9@:%._\\\\+~#=]{1,256}\\\\.[a-zA-Z0-9()]{1,6}\\\\b(?:[-a-zA-Z0-9()@:%_\\\\+.~#?&\\\\/=]*)$\")\nurls_blacklist = [\"wikipedia.org\", \"coursera.org\", \"google.com\", \"cyberleninka\", \"arxiv.org\"]\n\nfor p, doc, tokens in zip(final_predictions, ds[\"document\"], ds[\"tokens\"]):\n    for k in p:\n        \n        label_pred = id2label[str(np.argmax(p[k]))]\n        if \"B-URL\" in label_pred:\n            f = re.fullmatch(url_regex, tokens[k]) is not None\n            for u in urls_blacklist:\n                f = f and (u not in tokens[k])\n            if not f:\n                continue\n        if (\"B-NAME\" in label_pred) and not tokens[k].title() == tokens[k]:\n            continue\n\n        if label_pred != \"O\":\n            document.append(doc)\n            token.append(k)\n            label.append(label_pred)\n            token_str.append(tokens[k])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Часть меток была найдена с помощью реглярных выражений.","metadata":{}},{"cell_type":"code","source":"email_regex = re.compile(r'[\\w.+-]+@[\\w-]+\\.[\\w.-]+')\nphone_num_regex = re.compile(r\"(\\(\\d{3}\\)\\d{3}\\-\\d{4}\\w*|\\d{3}\\.\\d{3}\\.\\d{4})\\s\")\n\nfor d in ds:\n    for i, t in enumerate(d[\"tokens\"]):\n        if re.fullmatch(email_regex, t) is not None:\n            document.append(d[\"document\"])\n            token.append(i)\n            label.append(\"B-EMAIL\")\n            token_str.append(t)\n    \n    matches = phone_num_regex.findall(d[\"full_text\"])\n    if matches:\n        for match in matches:\n            i = 0\n            while i < len(d[\"tokens\"]):\n                if match.startswith(d[\"tokens\"][i]):\n                    cur_nums = [{\"document\": d[\"document\"], \"token\": i, \"label\": \"B-PHONE_NUM\", \"token_str\": d[\"tokens\"][i]}]\n                    res = d[\"tokens\"][i]\n                    i += 1\n                    while i < len(d[\"tokens\"]) and d[\"tokens\"][i] in match:\n                        cur_nums.append({\"document\": d[\"document\"], \"token\": i, \"label\": \"I-PHONE_NUM\", \"token_str\": d[\"tokens\"][i]})\n                        res += d[\"tokens\"][i]\n                        i += 1\n                    if res == match:\n                        for n in cur_nums:\n                            document.append(n[\"document\"])\n                            token.append(n[\"token\"])\n                            label.append(n[\"label\"])\n                            token_str.append(n[\"token_str\"])\n                else:\n                    i += 1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame({\n    \"document\": document,\n    \"token\": token,\n    \"label\": label,\n    \"token_str\": token_str\n})\n\ndf[\"row_id\"] = list(range(len(df)))\ndisplay(df.head(100))\ndf[[\"row_id\", \"document\", \"token\", \"label\"]].to_csv(\"submission.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]}]}